{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b071298",
   "metadata": {},
   "source": [
    "# Loading with ONE\n",
    "Once a session and datasets of interest have been identified, the ONE load methods can be used to load in the relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d3a58",
   "metadata": {},
   "source": [
    "To load all datasets for a given object we can use the load_object method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1897d0ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:18:54.747803Z",
     "iopub.status.busy": "2021-09-07T19:18:54.745197Z",
     "iopub.status.idle": "2021-09-07T19:18:58.720125Z",
     "shell.execute_reply": "2021-09-07T19:18:58.720125Z"
    }
   },
   "outputs": [],
   "source": [
    "from one.api import ONE\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org', silent=True)\n",
    "\n",
    "eid = 'CSH_ZAD_029/2020-09-19/001'\n",
    "trials = one.load_object(eid, 'trials') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff26fc",
   "metadata": {},
   "source": [
    "The attributes of returned object mirror the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4a2b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:18:58.726345Z",
     "iopub.status.busy": "2021-09-07T19:18:58.725319Z",
     "iopub.status.idle": "2021-09-07T19:18:58.737112Z",
     "shell.execute_reply": "2021-09-07T19:18:58.737112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['intervals', 'rewardVolume', 'contrastRight', 'response_times', 'choice', 'stimOn_times', 'probabilityLeft', 'goCueTrigger_times', 'intervals_bpod', 'goCue_times', 'firstMovement_times', 'stimOff_times', 'contrastLeft', 'feedbackType', 'feedback_times'])\n"
     ]
    }
   ],
   "source": [
    "print(trials.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8ec5d",
   "metadata": {},
   "source": [
    "If we only want to load in certain attributes of an object we can use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df12e76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:18:58.756412Z",
     "iopub.status.busy": "2021-09-07T19:18:58.749507Z",
     "iopub.status.idle": "2021-09-07T19:18:59.168162Z",
     "shell.execute_reply": "2021-09-07T19:18:59.169164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['intervals', 'rewardVolume', 'probabilityLeft', 'intervals_bpod'])\n"
     ]
    }
   ],
   "source": [
    "trials = one.load_object(eid, 'trials', attribute=['intervals', 'rewardVolume', 'probabilityLeft'])\n",
    "print(trials.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea30cf4c",
   "metadata": {},
   "source": [
    "If an object belongs to more than one collection, for example the clusters object, the collection must be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcbd040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:18:59.196985Z",
     "iopub.status.busy": "2021-09-07T19:18:59.179213Z",
     "iopub.status.idle": "2021-09-07T19:19:03.306484Z",
     "shell.execute_reply": "2021-09-07T19:19:03.307482Z"
    }
   },
   "outputs": [],
   "source": [
    "clusters = one.load_object(eid, 'clusters', collection='alf/probe01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e22e51",
   "metadata": {},
   "source": [
    "By default, the load_object method downloads and loads the data into memory, if you only want to download the data you can specify a download only flag. In this case the returned object will be a list of paths to the datasets on your local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd67dacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:19:03.348196Z",
     "iopub.status.busy": "2021-09-07T19:19:03.337479Z",
     "iopub.status.idle": "2021-09-07T19:19:04.383493Z",
     "shell.execute_reply": "2021-09-07T19:19:04.382672Z"
    }
   },
   "outputs": [],
   "source": [
    "files = one.load_object(eid, 'clusters', collection='alf/probe01', download_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c75c36",
   "metadata": {},
   "source": [
    "To load a single dataset we can use the load_dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ec972f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:19:04.392348Z",
     "iopub.status.busy": "2021-09-07T19:19:04.390593Z",
     "iopub.status.idle": "2021-09-07T19:19:04.520472Z",
     "shell.execute_reply": "2021-09-07T19:19:04.519475Z"
    }
   },
   "outputs": [],
   "source": [
    "reward_volume = one.load_dataset(eid, '_ibl_trials.rewardVolume.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f05b5",
   "metadata": {},
   "source": [
    "Once again if the same dataset exists in more than one collection, the collection must be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a75400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:19:04.538554Z",
     "iopub.status.busy": "2021-09-07T19:19:04.525952Z",
     "iopub.status.idle": "2021-09-07T19:19:04.648490Z",
     "shell.execute_reply": "2021-09-07T19:19:04.649487Z"
    }
   },
   "outputs": [],
   "source": [
    "waveforms = one.load_dataset(eid, 'clusters.waveforms.npy', collection='alf/probe01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4de0f",
   "metadata": {},
   "source": [
    "We can use the load_datasets method to load multiple datasets at once. This method returns two lists, the first which contains the data for each dataset and the second which contains meta information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6343ff03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:19:04.678768Z",
     "iopub.status.busy": "2021-09-07T19:19:04.668185Z",
     "iopub.status.idle": "2021-09-07T19:19:04.870657Z",
     "shell.execute_reply": "2021-09-07T19:19:04.871262Z"
    }
   },
   "outputs": [],
   "source": [
    "data, info = one.load_datasets(eid, datasets=['_ibl_trials.rewardVolume.npy',\n",
    "                                              '_ibl_trials.probabilityLeft.npy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b501ca",
   "metadata": {},
   "source": [
    "It is also possible to load datasets from different collections. For example if we want to simultaneously load a trials dataset and a clusters dataset we would type,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4afeb6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:19:04.883361Z",
     "iopub.status.busy": "2021-09-07T19:19:04.883015Z",
     "iopub.status.idle": "2021-09-07T19:19:05.108776Z",
     "shell.execute_reply": "2021-09-07T19:19:05.108776Z"
    }
   },
   "outputs": [],
   "source": [
    "data, info = one.load_datasets(eid, datasets=['_ibl_trials.rewardVolume.npy',\n",
    "                                              'clusters.waveforms.npy'],\n",
    "                               collections=['alf', 'alf/probe01'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e851f",
   "metadata": {},
   "source": [
    "More information about these methods can be found using the help command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dba137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-07T19:19:05.116167Z",
     "iopub.status.busy": "2021-09-07T19:19:05.115852Z",
     "iopub.status.idle": "2021-09-07T19:19:05.130374Z",
     "shell.execute_reply": "2021-09-07T19:19:05.129377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_dataset in module one.api:\n",
      "\n",
      "load_dataset(eid: Union[str, pathlib.Path, uuid.UUID], dataset: str, collection: Union[str, NoneType] = None, revision: Union[str, NoneType] = None, query_type: Union[str, NoneType] = None, download_only: bool = False, **kwargs) -> Any method of one.api.OneAlyx instance\n",
      "    Load a single dataset for a given session id and dataset name\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    eid : str, UUID, pathlib.Path, dict\n",
      "        Experiment session identifier; may be a UUID, URL, experiment reference string\n",
      "        details dict or Path.\n",
      "    dataset : str, dict\n",
      "        The ALF dataset to load.  May be a string or dict of ALF parts.  Supports asterisks as\n",
      "        wildcards.\n",
      "    collection : str\n",
      "        The collection to which the object belongs, e.g. 'alf/probe01'.\n",
      "        This is the relative path of the file from the session root.\n",
      "        Supports asterisks as wildcards.\n",
      "    revision : str\n",
      "        The dataset revision (typically an ISO date).  If no exact match, the previous\n",
      "        revision (ordered lexicographically) is returned.  If None, the default revision is\n",
      "        returned (usually the most recent revision).  Regular expressions/wildcards not\n",
      "        permitted.\n",
      "    query_type : str\n",
      "        Query cache ('local') or Alyx database ('remote')\n",
      "    download_only : bool\n",
      "        When true the data are downloaded and the file path is returned.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Dataset or a Path object if download_only is true.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    intervals = one.load_dataset(eid, '_ibl_trials.intervals.npy')\n",
      "    # Load dataset without specifying extension\n",
      "    intervals = one.load_dataset(eid, 'trials.intervals')  # wildcard mode only\n",
      "    intervals = one.load_dataset(eid, '*trials.intervals*')  # wildcard mode only\n",
      "    filepath = one.load_dataset(eid '_ibl_trials.intervals.npy', download_only=True)\n",
      "    spike_times = one.load_dataset(eid 'spikes.times.npy', collection='alf/probe01')\n",
      "    old_spikes = one.load_dataset(eid, 'spikes.times.npy',\n",
      "                                  collection='alf/probe01', revision='2020-08-31')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(one.load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2460b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "docs_executed": "executed",
  "kernelspec": {
   "display_name": "Python [conda env:iblenv_new] *",
   "language": "python",
   "name": "conda-env-iblenv_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
